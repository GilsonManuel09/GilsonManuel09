{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vamos utilizar o mlflow para versionar os nossos modelos "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook vai ser muito similar ao notebook `10_random_forests_mlflow.ipynb`, com a diferença que aqui vamos registar os nossos modelos no **Model Registry** do mlflow, que nos permite tê los versionados e as suas respectivas experiências e runs trackable.\n",
        "\n",
        "Referências:\n",
        "* [Model Registry](https://www.mlflow.org/docs/latest/model-registry.html#concepts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para perceber o que muda neste notebook será preciso percorrer o mesmo, e as alterações face ao notebook anterior irão ter um comentário em markdown antes das mesmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT_PATH = '../../data/'\n",
        "SEED = 42\n",
        "TARGET_COL = \"Outcome\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilizar o sqlite para fazer track das experiências"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A primeira coisa que vamos fazer é mudar onde as experiências vão ser guardadas.\n",
        "\n",
        "No notebook anterior estavamos a guarda las no local filesystem na pasta mlruns.\n",
        "\n",
        "**Para conseguirmos utilizar o model registry** já não vamos poder fazer isto, **temos que utilizar uma base de dados para guardar as experiências, como é referido na [documentação do mlflow](https://www.mlflow.org/docs/latest/tracking.html#backend-stores)**.\n",
        "\n",
        "O mlflow vem logo com suporte para utilizar o sqlite como database engine, e é o que iremos usar. \n",
        "\n",
        "Portanto vamos ter que mudar o `set_tracking_uri` para nos apontar para o ficheiro de database criado pelo sqlite corrido pelo mlflow. \n",
        "\n",
        "Nós ainda não temos nenhum ficheiro com uma DB mas isso não é um problema. O mlflow vai criar esse ficheiro com uma DB por nós, basta especificarmos o nomde do ficheiro de db que queremos crirar e ele no set vai cria-lo. \n",
        "\n",
        "Tendo em conta isto, no comando abaixo estamos a fazer set para a DB que deveria estar em `../../mlruns/mlflow.db` mas como este ficheiro não existe o mlflow vai criar uma nova db e guarda la nesse ficheiro.\n",
        "\n",
        "**Nota:** A db, caso não exista, não irá ser criado logo quando executam o comando abaixo, mas apenas quando criam uma experiência nessa db. \n",
        "\n",
        "Referências:\n",
        "* [Armazenamento dos dados da experiência](https://www.mlflow.org/docs/latest/tracking.html#backend-stores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"sqlite:///../../mlruns/mlflow.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criar ou reutilizar uma experiência"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos criar uma nova experiência agora que temos uma nova maneira de dar track às experiências.\n",
        "\n",
        "Não vamos conseguir utilizar a mesma experiência guardada no filesystem e na DB. **A experiência que guardamos no notebook anterior não está visivel na DB que criamos já que utilizamos outro mecanismo para a guardar.**\n",
        "\n",
        "Vamos especificar o `artifact_location` para que esta experiências não guarde os seus artefactos em `.\\mlruns` (na pasta dos notebooks) mas sim em `..\\..\\mlruns` (na root do projecto) \n",
        "\n",
        "**Nota:** Se já correram o notebook equivalente para a logistic regression então a experiment já foi criada lá, pelo que aqui só precisam de fazer o set dessa experiência"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location=('file:///c:/Users/gilso/OneDrive/Área de '\n",
              " 'Trabalho/rumos/notebooks/random_forest/../../mlruns/db'), creation_time=1701107536034, experiment_id='1', last_update_time=1701107536034, lifecycle_stage='active', name='Diabetes Prediction Experiment', tags={}>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "artifact_location = Path(\"../../mlruns/db\")\n",
        "\n",
        "# criar a pasta ../../mlruns/db caso ela não exista\n",
        "artifact_location.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    mlflow.create_experiment(name=\"Diabetes Prediction Experiment\", artifact_location=artifact_location.as_posix())\n",
        "except mlflow.MlflowException:\n",
        "    # experiência já foi criada, só precisamos de fazer set dela\n",
        "    pass\n",
        "\n",
        "mlflow.set_experiment(experiment_name=\"Diabetes Prediction Experiment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criar os datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = ROOT_PATH + 'diabetes_train.csv'\n",
        "test_path = ROOT_PATH + 'diabetes_test.csv'\n",
        "\n",
        "train_set = pd.read_csv(train_path)\n",
        "test_set = pd.read_csv(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:143: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
            "  return _dataset_source_registry.resolve(\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:143: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
            "  return _dataset_source_registry.resolve(\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = mlflow.data.from_pandas(train_set, source=train_path, targets=TARGET_COL, name=\"Diabetes Train Dataset\")\n",
        "test_dataset = mlflow.data.from_pandas(test_set, source=test_path, targets=TARGET_COL, name=\"Diabetes Test Dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criar uma run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ActiveRun: >"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.start_run(run_name=\"Random Forest Run\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardar datasets, modelos, artefactos, métricas e parametros da run - e **registar modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Guardamos a SEED utilizado como parametro\n",
        "\n",
        "mlflow.log_param(\"seed\", SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  return _infer_schema(self._df)\n"
          ]
        }
      ],
      "source": [
        "# Neste ponto guardarmos o dataset de treino e de teste associado à run\n",
        "\n",
        "mlflow.log_input(train_dataset, context=\"train\")\n",
        "mlflow.log_input(test_dataset, context=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train_set.drop([TARGET_COL], axis = 1)\n",
        "y_train = train_set[TARGET_COL]\n",
        "\n",
        "X_test = test_set.drop([TARGET_COL], axis = 1)\n",
        "y_test = test_set[TARGET_COL]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "features_names = X_train.columns\n",
        "\n",
        "X_train[features_names] = scaler.fit_transform(X_train)\n",
        "X_test[features_names] = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023/11/27 17:53:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x1ba2e4dd880>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vamos querer guardar também o scaler que usamos já que é uma parte vital do pre processamento de dados\n",
        "# e sem ele não conseguimos reproduzir os resultados\n",
        "# Como o StandardScaler é um modelo de sklearn vamos usar o mlflow.sklearn.log_model para o guardar\n",
        "\n",
        "mlflow.sklearn.log_model(scaler, \"std_scaler_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.275837</td>\n",
              "      <td>1.501997</td>\n",
              "      <td>0.424428</td>\n",
              "      <td>1.171912</td>\n",
              "      <td>0.818842</td>\n",
              "      <td>0.202551</td>\n",
              "      <td>1.388551</td>\n",
              "      <td>-0.256564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.597861</td>\n",
              "      <td>0.280560</td>\n",
              "      <td>0.525791</td>\n",
              "      <td>1.045640</td>\n",
              "      <td>2.323197</td>\n",
              "      <td>1.783641</td>\n",
              "      <td>-0.696657</td>\n",
              "      <td>0.975594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.306628</td>\n",
              "      <td>-0.659008</td>\n",
              "      <td>0.221703</td>\n",
              "      <td>-1.290397</td>\n",
              "      <td>-0.685512</td>\n",
              "      <td>-0.434985</td>\n",
              "      <td>-0.938791</td>\n",
              "      <td>1.139881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.858303</td>\n",
              "      <td>0.437154</td>\n",
              "      <td>-1.197374</td>\n",
              "      <td>-0.090810</td>\n",
              "      <td>-0.010585</td>\n",
              "      <td>-0.447736</td>\n",
              "      <td>0.488379</td>\n",
              "      <td>-0.995858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.306628</td>\n",
              "      <td>0.374516</td>\n",
              "      <td>1.944867</td>\n",
              "      <td>-1.290397</td>\n",
              "      <td>-0.685512</td>\n",
              "      <td>2.115160</td>\n",
              "      <td>-0.727992</td>\n",
              "      <td>0.236299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
              "0    -0.275837  1.501997       0.424428       1.171912  0.818842  0.202551   \n",
              "1     0.597861  0.280560       0.525791       1.045640  2.323197  1.783641   \n",
              "2     0.306628 -0.659008       0.221703      -1.290397 -0.685512 -0.434985   \n",
              "3    -0.858303  0.437154      -1.197374      -0.090810 -0.010585 -0.447736   \n",
              "4     0.306628  0.374516       1.944867      -1.290397 -0.685512  2.115160   \n",
              "\n",
              "   DiabetesPedigreeFunction       Age  \n",
              "0                  1.388551 -0.256564  \n",
              "1                 -0.696657  0.975594  \n",
              "2                 -0.938791  1.139881  \n",
              "3                  0.488379 -0.995858  \n",
              "4                 -0.727992  0.236299  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EFzppuepzzKB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(random_state = SEED).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x1ba2f4a0bb0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.sklearn.log_model(rf, artifact_path=\"random_forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c2O49gd00DEg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
          ]
        }
      ],
      "source": [
        "y_preds = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7368421052631579"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Glucose                     0.258462\n",
              "BMI                         0.180059\n",
              "Age                         0.144415\n",
              "DiabetesPedigreeFunction    0.106236\n",
              "BloodPressure               0.090174\n",
              "Pregnancies                 0.078640\n",
              "SkinThickness               0.072315\n",
              "Insulin                     0.069700\n",
              "dtype: float64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_imp = pd.Series(rf.feature_importances_, index = X_train.columns).sort_values(ascending = False)\n",
        "feature_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_imp_path = \"../../data/feature_importance.csv\"\n",
        "feature_imp.to_csv(feature_imp_path)\n",
        "mlflow.log_artifact(feature_imp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6MzRYWGj0WLx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(random_state = SEED)\n",
        "\n",
        "parameters = {'n_estimators': [10, 100, 300]}\n",
        "\n",
        "clf = GridSearchCV(rf, parameters, cv = 5).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x1ba2f6cc1c0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.sklearn.log_model(clf, artifact_path=\"grid_search_cv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMJ_jX7A04DZ",
        "outputId": "1737d1c4-8495-45e6-e9ca-b0332a2eaba1"
      },
      "outputs": [],
      "source": [
        "tunned_rf = clf.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tunned Random Forest Model\n",
        "\n",
        "Não vale a pena registarmos os modelos antes do fine tunning, mas **o modelo tunned definitvamente vamos querer registar !**\n",
        "\n",
        "Para o fazer, devem adicionar à chamada da função de `log_model` um argumento de **`registered_model_name`** com o nome que querem dar a este modelo. Neste caso vamos chamar ao model \"random_forest\".\n",
        "\n",
        "O comando abaixo irá criar a versão 1 deste modelo. Se correrem o mesmo comando mais vez ele irá criar novas versões do modelo. **Em qualquer experiência ou run em que registem um modelo com este mesmo nome ele irá criar uma nova versão do modelo.**\n",
        "\n",
        "Assim, o Model Registry permite ter uma visão centralizada dos modelos que temos e das suas respectivas versãos, sendo que **cada versão tem associada a si associada a sua run**, pelo que conseguimos perceber o que originou o modelo e qual a sua performance. \n",
        "\n",
        "Referências:\n",
        "* [mflow model api](https://www.mlflow.org/docs/latest/models.html#model-api)\n",
        "    * [mlflow.sklearn.log_model()](https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'random_forest' already exists. Creating a new version of this model...\n",
            "Created version '2' of model 'random_forest'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x1ba2f5e0850>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.sklearn.log_model(tunned_rf, \"tunned_rf\", registered_model_name=\"random_forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 300,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': 42,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tunned_rf.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'random_forester' already exists. Creating a new version of this model...\n",
            "Created version '2' of model 'random_forester'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x1ba2f52c5e0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.sklearn.log_model(tunned_rf, \"tunned_rf\", registered_model_name=\"random_forester\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HICyzOTi1FJH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\gilso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
          ]
        }
      ],
      "source": [
        "y_preds = tunned_rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_test, y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.log_metric(\"accuracy\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Opcional - Ver o modelo registado na UI do mlflow"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A UI do mlflow permite ver de forma visual todos os modelos registados até ao momento, qual é a útlima versão do mesmo e a que runs estão associados.\n",
        "\n",
        "Para correr a UI do mflow, tendo nós o modelo registado na db, temos que especificar esta db como a \"backend store\" em que temos os metados.\n",
        "\n",
        "Para correr a UI do mflow é necessário executar, na Anaconda Prompt na raiz deste projeto (pasta rumos) e tendo activo o ambiente utilizado neste projeto, o comando:\n",
        "\n",
        "`mlflow ui --backend-store-uri sqlite:///./mlruns/mlflow.db`\n",
        "\n",
        "**Nota:** O comando em cima irá iniciar a UI de mlflow na porta 5000. Caso queiram mudar esta porta devem acrescentar `--port <PORT>` ao comando (em que <PORT> deve ser substituido pela porta desejada). \n",
        "\n",
        "O comando acima não irá funcionar caso tenham tido alguns problemas no Windows com a instalação do mlflow, mas como o título desta secção indica este passo é apenas opcional e não irá ser avaliado.\n",
        "\n",
        "Após executarem este comando, vão poder ver a UI do mlflow no vosso browser acedendo a \n",
        "\n",
        "`localhost:5000`\n",
        "\n",
        "(se tiverem alterado a porta em que o mlflow UI é iniciado então devem de alterar também aqui o 5000 por essa porta)\n",
        "\n",
        "Na tab de `Models` podem explorar os modelos que registaram."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "09_random_forests.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('rumos-class-oml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5a97069f8d9d8e941bb8a3a542a648f8b4bcb13721f1771979b015a903dcf22b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
